{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1",
    "collapsed": false
   },
   "source": "# Import python packages\nimport pandas as pd\nfrom config import input_files, output_tables, database, schema  # Import the config\n\n\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "68b017c5-3542-42ce-869f-aa5a2dd9556f",
   "metadata": {
    "name": "cell2",
    "collapsed": false
   },
   "source": "# To Load Multiple Tables"
  },
  {
   "cell_type": "code",
   "id": "484cfcc5-84e5-43ac-b124-7df9ba881d1d",
   "metadata": {
    "language": "python",
    "name": "cell3",
    "collapsed": false
   },
   "outputs": [],
   "source": "\nZ = database+'.'+schema+'.'\n\n# Loop through each input file and output table\nfor input_file, output_table in zip(input_files, output_tables):\n    # Read the CSV file into a DataFrame\n    df = pd.read_csv(input_file)\n    \n    # Create a Snowpark DataFrame from the Pandas DataFrame\n    snowpark_df = session.create_dataframe(df)\n    \n    # Write the Snowpark DataFrame to Snowflake, overwriting if the table exists\n    snowpark_df.write.mode(\"overwrite\").save_as_table(Z+output_table)\n    \n    print(f\"DataFrame from {input_file} saved to Snowflake table {output_table}\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "44dd828c-9e39-4e3e-8816-c9a30d67b183",
   "metadata": {
    "name": "cell4",
    "collapsed": false
   },
   "source": "# To Load Single Table"
  },
  {
   "cell_type": "code",
   "id": "84ad468c-fd84-46b1-a957-b207f3c9e7e6",
   "metadata": {
    "language": "python",
    "name": "cell5",
    "collapsed": false
   },
   "outputs": [],
   "source": "input_file = 'FILES/INPUT_FILE.csv'\noutput_table = 'OUTPUT_TABLE'\n\nX = database+'.'+schema+'.'\n\n\ndf = pd.read_csv(input_file)\n    \n# Create a Snowpark DataFrame from the Pandas DataFrame\nsnowpark_df = session.create_dataframe(df)\n    \n# Write the Snowpark DataFrame to Snowflake, overwriting if the table exists\nsnowpark_df.write.mode(\"overwrite\").save_as_table(X+output_table)\n\nprint(f\"DataFrame from {input_file} saved to Snowflake table {X+output_table}\")",
   "execution_count": null
  }
 ]
}
